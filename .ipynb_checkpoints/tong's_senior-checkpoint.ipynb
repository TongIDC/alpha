{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callApi(date):\n",
    "    key = \"2b423d0c90e52bb805ccf6af1f305d7c\"\n",
    "    latitude = \"13.8282\"\n",
    "    longitude = \"100.614\"\n",
    "    time = str(date).replace(\" \", \"T\")\n",
    "    url = \"https://api.darksky.net/forecast/{}/{},{},{}\".format(key, latitude, longitude, time)\n",
    "    \n",
    "    response = requests.get(url=url)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_month(month, year):\n",
    "    date = datetime.datetime(year=year, month=month, day=29)\n",
    "    nextMonth = date.month + 1\n",
    "    while(date.month != nextMonth):\n",
    "        yield date\n",
    "        date = date + datetime.timedelta(days=1)   \n",
    "        \n",
    "def one_day(date):\n",
    "    tomorrow = date + datetime.timedelta(days=1)\n",
    "    while(date.day != tomorrow.day):\n",
    "        yield date\n",
    "        date = date + datetime.timedelta(minutes=15)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(filename, data):\n",
    "    with open(\"tongsdata/\" + filename + \".json\", \"w\", encoding='utf-8') as fout:\n",
    "        fout.write(json.dumps(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "year=2018\n",
    "month=11\n",
    "date = datetime.datetime(year=year, month=month, day=30)\n",
    "nextMonth = date.month + 1\n",
    "while(date.month != nextMonth):\n",
    "    date = date + datetime.timedelta(days=1)  \n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LOAD INTO FILES\n",
    "\n",
    "for day in one_month(11, 2018):\n",
    "    day_result = {}\n",
    "    filename = day.strftime(\"%d-%m-%Y\")\n",
    "    for minute in one_day(day):\n",
    "        result = callApi(minute)\n",
    "        day_result.update({ minute.strftime(\"%H:%M\"): result.json()})  #  key is time of the day\n",
    "    write_json(filename=filename, data=day_result)  #  filename is date    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDayDataframe(filename):\n",
    "    path = \"tongsdata/\"\n",
    "    filedate = filename.split(\".\")[0].split(\"-\")\n",
    "\n",
    "    with open(path + filename, 'r', encoding='utf-8') as fin:\n",
    "        data_json = json.loads(fin.read())\n",
    "\n",
    "    #  Create X DataFrame\n",
    "    todayData = {time: data_json[time]['currently'] for time in data_json}\n",
    "    todayData_DF = pd.DataFrame(todayData).T\n",
    "\n",
    "    #  Create y DataFrame\n",
    "    energyBalanceFilename = \"energyBalance/Energy_Balance_{}_{}_{}.csv\".format(filedate[2], filedate[1], filedate[0])\n",
    "    energyBalance = pd.read_csv(path + energyBalanceFilename, delimiter=\";\")\n",
    "\n",
    "    energyBalance_DF = pd.DataFrame(index=energyBalance.iloc[:-1,0].apply(lambda x: x[2:-1]))\n",
    "    energyBalance_DF['PV Power Generation'] = energyBalance['PV power generation / Mean values [W]  '].values[:-1]\n",
    "    energyBalance_DF = energyBalance_DF[energyBalance_DF != ' ']\n",
    "    energyBalance_DF = energyBalance_DF.dropna()\n",
    "    \n",
    "    #  Join X y DataFrame\n",
    "    data = todayData_DF.join(energyBalance_DF)\n",
    "    return data\n",
    "\n",
    "def cleanDataframe(masterDF):\n",
    "    masterData_cleaned = masterDF.reset_index()\n",
    "    masterData_cleaned = masterData_cleaned.rename(columns={'index': 'time_of_day'})\n",
    "    masterData_cleaned = masterData_cleaned[masterData_cleaned['PV Power Generation'].notna()]\n",
    "    masterData_cleaned['month'] = masterData_cleaned['time'].apply(datetime.datetime.fromtimestamp).apply(lambda x: x.month)\n",
    "    masterData_cleaned['cloudCover'] = masterData_cleaned['cloudCover'].fillna(value=masterData_cleaned['cloudCover'].mean())\n",
    "    masterData_cleaned['PV Power Generation'] = masterData_cleaned['PV Power Generation'].apply(lambda x: x.replace(\",\", \"\")).astype('float')\n",
    "    return masterData_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureEngineering(masterDF):\n",
    "    masterDF = masterDF.drop(columns=['icon', 'summary', 'time', 'windBearing', 'windGust', 'ozone', 'precipIntensity', 'precipProbability','pressure'])\n",
    "    masterDF = pd.get_dummies(masterDF, columns=['time_of_day', 'precipType', 'uvIndex', 'month'])\n",
    "    return masterDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-11-2018.json (47, 15)\n",
      "02-11-2018.json (47, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-11-2018.json (47, 15)\n",
      "04-11-2018.json (47, 14)\n",
      "05-11-2018.json (47, 14)\n",
      "06-11-2018.json (47, 15)\n",
      "07-11-2018.json (47, 14)\n",
      "08-11-2018.json (47, 15)\n",
      "09-11-2018.json (47, 14)\n",
      "10-11-2018.json (47, 15)\n",
      "11-11-2018.json (47, 14)\n",
      "12-11-2018.json (47, 15)\n",
      "13-11-2018.json (47, 14)\n",
      "14-11-2018.json (47, 15)\n",
      "15-11-2018.json (47, 15)\n",
      "16-11-2018.json (47, 15)\n",
      "17-11-2018.json (47, 14)\n",
      "18-11-2018.json (47, 15)\n",
      "19-11-2018.json (47, 15)\n",
      "20-11-2018.json (47, 14)\n",
      "21-11-2018.json (47, 15)\n",
      "22-11-2018.json (47, 15)\n",
      "23-11-2018.json (47, 15)\n",
      "24-11-2018.json (47, 19)\n",
      "25-11-2018.json (47, 19)\n",
      "26-11-2018.json (47, 19)\n",
      "27-11-2018.json (47, 19)\n",
      "28-11-2018.json (47, 19)\n",
      "29-11-2018.json (47, 15)\n",
      "30-11-2018.json (47, 14)\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"tongsdata/\")\n",
    "\n",
    "#files.remove(\".DS_Store\")\n",
    "files.remove(\"energyBalance\")\n",
    "\n",
    "masterData = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    r = createDayDataframe(file).loc['06:30':'18:00']\n",
    "    print(file, r.shape)\n",
    "    masterData = pd.concat([masterData, r], axis=0)\n",
    "    \n",
    "masterData = cleanDataframe(masterData)\n",
    "masterData = featureEngineering(masterData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393, 67)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1393 entries, 0 to 1409\n",
      "Data columns (total 67 columns):\n",
      "PV Power Generation    1393 non-null float64\n",
      "apparentTemperature    1389 non-null object\n",
      "cloudCover             1393 non-null float64\n",
      "dewPoint               1389 non-null object\n",
      "humidity               1389 non-null object\n",
      "temperature            1389 non-null object\n",
      "visibility             1388 non-null object\n",
      "windSpeed              1388 non-null object\n",
      "time_of_day_06:30      1393 non-null uint8\n",
      "time_of_day_06:45      1393 non-null uint8\n",
      "time_of_day_07:00      1393 non-null uint8\n",
      "time_of_day_07:15      1393 non-null uint8\n",
      "time_of_day_07:30      1393 non-null uint8\n",
      "time_of_day_07:45      1393 non-null uint8\n",
      "time_of_day_08:00      1393 non-null uint8\n",
      "time_of_day_08:15      1393 non-null uint8\n",
      "time_of_day_08:30      1393 non-null uint8\n",
      "time_of_day_08:45      1393 non-null uint8\n",
      "time_of_day_09:00      1393 non-null uint8\n",
      "time_of_day_09:15      1393 non-null uint8\n",
      "time_of_day_09:30      1393 non-null uint8\n",
      "time_of_day_09:45      1393 non-null uint8\n",
      "time_of_day_10:00      1393 non-null uint8\n",
      "time_of_day_10:15      1393 non-null uint8\n",
      "time_of_day_10:30      1393 non-null uint8\n",
      "time_of_day_10:45      1393 non-null uint8\n",
      "time_of_day_11:00      1393 non-null uint8\n",
      "time_of_day_11:15      1393 non-null uint8\n",
      "time_of_day_11:30      1393 non-null uint8\n",
      "time_of_day_11:45      1393 non-null uint8\n",
      "time_of_day_12:00      1393 non-null uint8\n",
      "time_of_day_12:15      1393 non-null uint8\n",
      "time_of_day_12:30      1393 non-null uint8\n",
      "time_of_day_12:45      1393 non-null uint8\n",
      "time_of_day_13:00      1393 non-null uint8\n",
      "time_of_day_13:15      1393 non-null uint8\n",
      "time_of_day_13:30      1393 non-null uint8\n",
      "time_of_day_13:45      1393 non-null uint8\n",
      "time_of_day_14:00      1393 non-null uint8\n",
      "time_of_day_14:15      1393 non-null uint8\n",
      "time_of_day_14:30      1393 non-null uint8\n",
      "time_of_day_14:45      1393 non-null uint8\n",
      "time_of_day_15:00      1393 non-null uint8\n",
      "time_of_day_15:15      1393 non-null uint8\n",
      "time_of_day_15:30      1393 non-null uint8\n",
      "time_of_day_15:45      1393 non-null uint8\n",
      "time_of_day_16:00      1393 non-null uint8\n",
      "time_of_day_16:15      1393 non-null uint8\n",
      "time_of_day_16:30      1393 non-null uint8\n",
      "time_of_day_16:45      1393 non-null uint8\n",
      "time_of_day_17:00      1393 non-null uint8\n",
      "time_of_day_17:15      1393 non-null uint8\n",
      "time_of_day_17:30      1393 non-null uint8\n",
      "time_of_day_17:45      1393 non-null uint8\n",
      "time_of_day_18:00      1393 non-null uint8\n",
      "precipType_rain        1393 non-null uint8\n",
      "uvIndex_0              1393 non-null uint8\n",
      "uvIndex_1              1393 non-null uint8\n",
      "uvIndex_2              1393 non-null uint8\n",
      "uvIndex_3              1393 non-null uint8\n",
      "uvIndex_4              1393 non-null uint8\n",
      "uvIndex_5              1393 non-null uint8\n",
      "uvIndex_6              1393 non-null uint8\n",
      "uvIndex_7              1393 non-null uint8\n",
      "uvIndex_8              1393 non-null uint8\n",
      "uvIndex_9              1393 non-null uint8\n",
      "month_11               1393 non-null uint8\n",
      "dtypes: float64(2), object(6), uint8(59)\n",
      "memory usage: 178.2+ KB\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "masterData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y\n",
    "    * 'PV Power Generation'\n",
    "\n",
    "X\n",
    "    * 'time_of_day'         ->  one-hot\n",
    "    * 'apparentTemperature' ->  OK\n",
    "    * 'cloudCover'          ->  OK \n",
    "    * 'dewPoint'            ->  OK\n",
    "    * 'humidity'            ->  OK\n",
    "    * 'icon'                ->  drop\n",
    "    * 'precipType'          ->  one-hot\n",
    "    * 'summary'             ->  drop\n",
    "    * 'temperature'         ->  OK\n",
    "    * 'time'                ->  drop\n",
    "    * 'uvIndex'             ->  one-hot\n",
    "    * 'visibility'          ->  OK\n",
    "    * 'windBearing'         ->  drop (NN NE EE ...)\n",
    "    * 'windGust'            ->  drop (what is wind gust?)\n",
    "    * 'windSpeed'           ->  OK\n",
    "    * 'month'               ->  one-hot (Should do season or quarter?)\n",
    "    * 'ozone'               ->  drop (why less data)\n",
    "    * 'precipIntensity'     ->  drop (why less data)\n",
    "    * 'precipProbability'   ->  drop (why less data)\n",
    "    * 'pressure'            ->  drop (why less data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(masterData.drop(columns=['PV Power Generation']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterData = masterData.dropna()\n",
    "\n",
    "X = masterData.drop(columns=['PV Power Generation']).astype('float').values\n",
    "y = masterData['PV Power Generation'].astype('float').values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterData.to_csv(\"masterData_11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1388, 66)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR = LR.fit(X_train, y_train)\n",
    "\n",
    "y_hat = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367.6810834221374"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "math.sqrt(mean_squared_error(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['Actual'] = y_test\n",
    "result['Prediction'] = y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result\n",
    "result.to_csv(\"result2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBRegressor is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=330, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -105775.4419997663\n",
      "Generation 2 - Current best internal CV score: -104715.5640267997\n",
      "Generation 3 - Current best internal CV score: -102922.85849748194\n",
      "Generation 4 - Current best internal CV score: -97264.4468309271\n",
      "Generation 5 - Current best internal CV score: -96071.53541158461\n",
      "Generation 6 - Current best internal CV score: -95969.96946055714\n",
      "Generation 7 - Current best internal CV score: -90565.14997834575\n",
      "Generation 8 - Current best internal CV score: -90565.14997834575\n",
      "Generation 9 - Current best internal CV score: -90554.09064087698\n",
      "Generation 10 - Current best internal CV score: -90554.09064087698\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(ExtraTreesRegressor(input_matrix, bootstrap=False, max_features=0.55, min_samples_leaf=4, min_samples_split=14, n_estimators=100), bootstrap=False, max_features=0.8, min_samples_leaf=6, min_samples_split=7, n_estimators=100)\n",
      "-98727.50753663958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "tpot = TPOTRegressor(generations=10, population_size=30, verbosity=2) # more generation, pop size will make it closer,but it will take more time\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('best_model_30days_5.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 3 RandomForestRegressor(only 1 estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71197.40161996237 192.84444956772336 0.8393134764406354\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = train_test_split(X, y)\n",
    "\n",
    "# Average CV score on the training set was:-91867.4890210794\n",
    "exported_pipeline = RandomForestRegressor(bootstrap=False, max_features=0.3, min_samples_leaf=1, min_samples_split=7, n_estimators=100)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score ,mean_absolute_error\n",
    "print(mean_squared_error(results, testing_target), \n",
    "mean_absolute_error(results, testing_target), \n",
    "r2_score(results, testing_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 4 StackingEstimator(2 estimators) better mse, mae, r2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82411.68873688129 185.46956724303556 0.8431508099074713\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from tpot.builtins import StackingEstimator, ZeroCount\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = train_test_split(X, y)\n",
    "\n",
    "# Average CV score on the training set was:-87019.59662711709\n",
    "exported_pipeline = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),\n",
    "    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=False, max_features=0.5, min_samples_leaf=3, min_samples_split=8, n_estimators=100)),\n",
    "    ZeroCount(),\n",
    "    RandomForestRegressor(bootstrap=False, max_features=0.15000000000000002, min_samples_leaf=2, min_samples_split=6, n_estimators=100)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score ,mean_absolute_error\n",
    "print(mean_squared_error(results, testing_target), \n",
    "mean_absolute_error(results, testing_target), \n",
    "r2_score(results, testing_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87369.62423989213 198.87958467069757 0.8162386602211584\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = train_test_split(X, y)\n",
    "\n",
    "# Average CV score on the training set was:-90554.09064087698\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=False, max_features=0.55, min_samples_leaf=4, min_samples_split=14, n_estimators=100)),\n",
    "    ExtraTreesRegressor(bootstrap=False, max_features=0.8, min_samples_leaf=6, min_samples_split=7, n_estimators=100)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "from sklearn.metrics import mean_squared_error, r2_score ,mean_absolute_error\n",
    "print(mean_squared_error(results, testing_target), \n",
    "mean_absolute_error(results, testing_target), \n",
    "r2_score(results, testing_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213.94625504322767"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score ,mean_absolute_error\n",
    "mean_squared_error(results, testing_target)\n",
    "mean_absolute_error(results, testing_target)\n",
    "#r2_score(results, testing_target)\n",
    "#mean_absolute_percentage_error(testing_target, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>uvIndex_0</td>\n",
       "      <td>0.315219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>humidity</td>\n",
       "      <td>0.099506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temperature</td>\n",
       "      <td>0.087068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>uvIndex_1</td>\n",
       "      <td>0.082377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apparentTemperature</td>\n",
       "      <td>0.058746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature Name  Importance\n",
       "55            uvIndex_0    0.315219\n",
       "3              humidity    0.099506\n",
       "4           temperature    0.087068\n",
       "56            uvIndex_1    0.082377\n",
       "0   apparentTemperature    0.058746"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.feature_selection import SelectFromModel\n",
    "featuresImportance = pd.DataFrame()\n",
    "featuresImportance['Feature Name'] = features\n",
    "featuresImportance['Importance'] = exported_pipeline.feature_importances_\n",
    "\n",
    "featuresImportance.sort_values('Importance', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['Actual'] = testing_target\n",
    "result['Prediction'] = results\n",
    "result['Error'] = np.abs(testing_target - results)\n",
    "result.to_csv(\"result_tpot_30days_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edaData = masterData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.21\n",
       "1      3.21\n",
       "2      3.25\n",
       "3      3.25\n",
       "4      3.24\n",
       "5      3.25\n",
       "6      3.25\n",
       "7      2.93\n",
       "8      3.28\n",
       "9      4.13\n",
       "10     5.25\n",
       "11     5.44\n",
       "12     5.62\n",
       "13     5.81\n",
       "14        6\n",
       "15     6.73\n",
       "16     7.46\n",
       "17     8.19\n",
       "18     8.92\n",
       "19     8.75\n",
       "20     8.65\n",
       "21     8.61\n",
       "22     8.66\n",
       "23      8.7\n",
       "24     8.78\n",
       "25     8.89\n",
       "26     9.04\n",
       "27     8.78\n",
       "28     8.52\n",
       "29     8.27\n",
       "       ... \n",
       "439    6.56\n",
       "440    6.63\n",
       "441    6.73\n",
       "442    6.29\n",
       "443    5.88\n",
       "444    5.49\n",
       "445    5.13\n",
       "446    5.41\n",
       "447     5.7\n",
       "448       6\n",
       "449     6.3\n",
       "450    6.89\n",
       "451    7.56\n",
       "452    8.27\n",
       "453    9.03\n",
       "454    8.41\n",
       "455    7.81\n",
       "456    7.26\n",
       "457    6.75\n",
       "458    6.99\n",
       "459    7.34\n",
       "460    7.77\n",
       "461    8.27\n",
       "462    7.85\n",
       "463    7.45\n",
       "464    7.08\n",
       "465    6.75\n",
       "466    6.73\n",
       "467    6.72\n",
       "468    6.73\n",
       "Name: windSpeed, Length: 465, dtype: object"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edaData['windSpeed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
